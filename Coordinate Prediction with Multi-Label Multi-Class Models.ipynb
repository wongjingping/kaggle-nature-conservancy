{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-Valued Coordinate Prediction Using Multi-Label Multi-Class Models\n",
    "\n",
    "This notebook aims to predict coordinates using multi-label multi-class models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# system libraries\n",
    "import os\n",
    "from glob import glob\n",
    "import logging\n",
    "\n",
    "# numerical,image and plotting stuff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "import skimage.transform as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a length-w\\*w vector which we want to get the x and y coordinates of the entry with the highest signal.\n",
    "\n",
    "x1, x2,              ... xw,\n",
    "\n",
    "xw+1, xw+2,          ... x2w,\n",
    "\n",
    "...\n",
    "\n",
    "x(w-1)w+1, x(w-1)w+2,... xw\\*w\n",
    "\n",
    "y1 would be a w-vector indicating the x coordinate with the signal, y2 would be the corresponding w-vector for the y-coordinate.\n",
    "\n",
    "we will train the inputs on 2 fc layers and then learn the coordinates. Each output y would have its own softmax stacked on top of the final fc layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(0)\n",
    "n = 1000000\n",
    "w = 10\n",
    "X = np.round(rng.uniform(low=-1,high=1,size=(n,w*w)),decimals=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how our input data will look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.1 ,  0.43,  0.21,  0.09, -0.15,  0.29, -0.12,  0.78,  0.93,\n",
       "         -0.23],\n",
       "        [ 0.58,  0.06,  0.14,  0.85, -0.86, -0.83, -0.96,  0.67,  0.56,\n",
       "          0.74],\n",
       "        [ 0.96,  0.6 , -0.08,  0.56, -0.76,  0.28, -0.71,  0.89,  0.04,\n",
       "         -0.17],\n",
       "        [-0.47,  0.55, -0.09,  0.14, -0.96,  0.24,  0.22,  0.23,  0.89,\n",
       "          0.36],\n",
       "        [-0.28, -0.13,  0.4 , -0.88,  0.33,  0.34, -0.58, -0.74, -0.37,\n",
       "         -0.27],\n",
       "        [ 0.14, -0.12,  0.98, -0.8 , -0.58, -0.68,  0.31, -0.49, -0.07,\n",
       "         -0.51],\n",
       "        [-0.68, -0.78,  0.31, -0.72, -0.61, -0.26,  0.64, -0.81,  0.68,\n",
       "         -0.81],\n",
       "        [ 0.95, -0.06,  0.95,  0.21,  0.48, -0.92, -0.43, -0.76, -0.41,\n",
       "         -0.76],\n",
       "        [-0.36, -0.17, -0.87,  0.38,  0.13, -0.47,  0.05, -0.81,  0.15,\n",
       "          0.86],\n",
       "        [-0.36,  0.33, -0.74,  0.43, -0.42, -0.63,  0.17, -0.96,  0.66,\n",
       "         -0.99]],\n",
       "\n",
       "       [[ 0.36, -0.46,  0.47,  0.92, -0.5 ,  0.15,  0.18,  0.14, -0.55,\n",
       "          0.91],\n",
       "        [-0.11,  0.69,  0.4 , -0.41,  0.63, -0.21,  0.76,  0.16,  0.76,\n",
       "          0.39],\n",
       "        [ 0.45,  0.  ,  0.91,  0.29, -0.15,  0.21, -0.96, -0.4 ,  0.32,\n",
       "         -0.42],\n",
       "        [ 0.24, -0.14, -0.73, -0.4 ,  0.14,  0.18,  0.15,  0.31,  0.3 ,\n",
       "         -0.14],\n",
       "        [ 0.79, -0.26, -0.13,  0.78,  0.61,  0.41, -0.8 ,  0.84,  0.43,  1.  ],\n",
       "        [-0.7 ,  0.74, -0.68,  0.23, -0.75,  0.7 ,  0.61,  0.14, -0.19,\n",
       "         -0.86],\n",
       "        [ 0.39, -0.09,  0.44,  0.73,  0.95,  0.71, -0.98, -0.28,  0.46,\n",
       "         -0.66],\n",
       "        [ 0.04, -0.89, -0.6 , -0.96,  0.59, -0.55, -0.31,  0.86,  0.41,\n",
       "         -0.94],\n",
       "        [-0.67,  0.24,  0.15, -0.52,  0.87,  0.23,  0.07,  0.18,  0.46,\n",
       "         -0.38],\n",
       "        [-0.2 , -0.58, -0.63,  0.89,  0.48, -0.02, -0.55, -0.49, -0.88,\n",
       "         -0.13]],\n",
       "\n",
       "       [[-0.38,  0.39, -0.24, -0.64, -0.95, -0.87,  0.36, -0.09,  0.07,\n",
       "          0.79],\n",
       "        [ 0.98, -0.57,  0.33, -0.47, -0.96,  0.52, -0.36, -0.23,  0.18,\n",
       "          0.66],\n",
       "        [ 0.26,  0.75, -0.45,  0.6 , -0.63,  0.91,  0.37, -0.57,  0.89,\n",
       "          0.46],\n",
       "        [-0.49, -0.57,  0.04, -0.95, -0.59, -0.15, -0.25, -0.07, -0.44,\n",
       "          0.17],\n",
       "        [ 0.73, -0.76,  0.03, -0.74,  0.43, -0.21,  0.13, -0.63, -0.71,\n",
       "         -0.02],\n",
       "        [-0.29,  0.88,  0.53,  0.5 ,  0.81, -0.83,  0.1 ,  0.17,  0.92,\n",
       "         -0.42],\n",
       "        [-0.52, -0.8 , -0.97,  0.86,  0.34,  0.57, -0.44,  0.17, -0.87,\n",
       "         -0.03],\n",
       "        [ 0.95,  0.75, -0.32,  0.92, -0.54,  0.9 ,  0.88,  0.6 ,  0.26,\n",
       "          0.75],\n",
       "        [-0.41,  0.7 ,  0.24, -0.97, -0.31, -0.7 ,  0.96, -0.04, -0.01,\n",
       "          0.28],\n",
       "        [-0.26, -0.73,  0.64, -0.62,  0.02, -0.55, -0.8 ,  0.72,  0.95,\n",
       "          0.92]],\n",
       "\n",
       "       [[ 0.81,  0.55, -0.33, -0.84, -0.19, -0.54, -0.74, -0.89,  0.45,\n",
       "         -0.98],\n",
       "        [ 0.54, -0.71, -0.84, -0.82,  0.34, -0.51, -0.16,  0.11,  0.72,\n",
       "          0.45],\n",
       "        [-0.46, -0.74, -0.89, -0.4 , -0.48, -0.09,  0.37,  0.39, -0.43,\n",
       "         -0.24],\n",
       "        [-0.64,  0.58, -0.89,  0.39,  0.56,  0.55, -0.48, -0.25,  0.18,\n",
       "         -0.45],\n",
       "        [-0.26, -0.61, -0.08, -0.91,  0.6 , -0.85,  0.04, -0.39,  0.16,\n",
       "          0.92],\n",
       "        [ 0.29, -0.93, -0.14,  0.02,  0.07,  0.36, -0.44, -0.74, -0.21,\n",
       "          0.91],\n",
       "        [-0.63,  0.81,  0.09, -0.09,  0.76, -0.08,  0.45, -0.2 ,  0.81,\n",
       "          0.38],\n",
       "        [ 0.4 , -0.34,  0.51,  0.27, -0.52, -0.68,  0.59,  0.92, -0.08,\n",
       "          0.18],\n",
       "        [ 0.72, -0.09,  0.9 ,  0.15,  0.64,  0.82,  0.63, -0.68,  0.26,\n",
       "         -0.2 ],\n",
       "        [-0.87, -0.15, -0.48,  0.7 , -0.93,  0.92, -0.29, -0.29, -0.97,\n",
       "         -0.63]],\n",
       "\n",
       "       [[-0.2 ,  0.86, -0.8 ,  0.89,  0.74, -0.09, -0.35, -0.53,  0.23,\n",
       "         -0.93],\n",
       "        [-0.97, -0.14, -0.86, -0.5 , -0.56, -0.49, -0.74, -0.98, -0.77,\n",
       "          0.24],\n",
       "        [ 0.95,  0.98, -0.18, -0.67,  0.28, -0.02,  0.98, -0.87,  0.57,\n",
       "         -0.42],\n",
       "        [-0.52,  0.33, -0.51,  0.33,  0.03, -0.15,  0.11, -0.43,  0.41,\n",
       "         -0.17],\n",
       "        [-0.28,  0.66,  0.85, -0.91, -0.53, -0.3 ,  0.63,  0.97,  0.94,\n",
       "          0.81],\n",
       "        [-0.41,  0.98, -0.5 , -0.79,  0.9 , -0.53,  0.38, -0.88,  0.46,\n",
       "          0.76],\n",
       "        [-0.46, -0.24, -0.25,  0.5 , -0.52, -0.66, -0.1 , -0.39,  0.68,\n",
       "         -0.52],\n",
       "        [ 0.  ,  0.89,  0.27,  0.73,  0.88,  0.5 ,  0.4 ,  0.94,  0.99,\n",
       "         -0.1 ],\n",
       "        [-0.86, -0.41, -0.7 , -0.17, -0.74,  0.21, -0.23,  0.79,  0.94,\n",
       "          0.09],\n",
       "        [-0.45,  0.18,  0.79, -0.19,  0.1 , -0.46, -0.09, -0.2 , -0.5 ,\n",
       "          0.01]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0:5,:].reshape((5,w,w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5]\n",
      " [4]\n",
      " [1]\n",
      " [4]\n",
      " [7]]\n",
      "[[2]\n",
      " [9]\n",
      " [0]\n",
      " [9]\n",
      " [8]]\n"
     ]
    }
   ],
   "source": [
    "# prepare Y outputs for regression\n",
    "y1 = np.int16(X.argmax(axis=1)/w).reshape((n,1))\n",
    "y2 = np.int16(X.argmax(axis=1)%w).reshape((n,1))\n",
    "print(y1[0:5])\n",
    "print(y2[0:5])\n",
    "Y_reg = np.hstack((y1,y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]]\n",
      "[[ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]]\n",
      "[[ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  1.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "y1 = np.int16(X.argmax(axis=1)/w).reshape((n,1))\n",
    "y2 = np.int16(X.argmax(axis=1)%w).reshape((n,1))\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "enc.fit(np.arange(w).reshape(w,1))\n",
    "y1 = enc.transform(y1)\n",
    "y2 = enc.transform(y2)\n",
    "print(y1[0:5,:])\n",
    "print(y2[0:5,:])\n",
    "Y_sm = np.hstack([y1,y2])\n",
    "Y_sm_half = np.hstack([y1,y2])\n",
    "print(Y_sm[0:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by testing a model with a softmax on the top, combining over both coordinate outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers.pooling import MaxPooling1D\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "\n",
    "m_sm = Sequential([\n",
    "    Dense(16, input_dim=w*w),\n",
    "    Activation('tanh'),\n",
    "    Dropout(0.2),\n",
    "    Dense(16, input_dim=8),\n",
    "    Activation('tanh'),\n",
    "    Dropout(0.2),\n",
    "    Dense(2*w),\n",
    "    Activation('softmax'),\n",
    "])\n",
    "\n",
    "m_reg = Sequential([\n",
    "    Dense(16, input_dim=w*w),\n",
    "    Activation('tanh'),\n",
    "    Dropout(0.2),\n",
    "    Dense(16, input_dim=8),\n",
    "    Activation('tanh'),\n",
    "    Dropout(0.2),\n",
    "    Dense(2),\n",
    "    Activation('linear'),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800000 samples, validate on 200000 samples\n",
      "Epoch 1/3\n",
      "800000/800000 [==============================] - 40s - loss: 8.0633 - mean_absolute_error: 2.4492 - val_loss: 8.0113 - val_mean_absolute_error: 2.4454\n",
      "Epoch 2/3\n",
      "800000/800000 [==============================] - 43s - loss: 8.0324 - mean_absolute_error: 2.4448 - val_loss: 7.9986 - val_mean_absolute_error: 2.4420\n",
      "Epoch 3/3\n",
      "800000/800000 [==============================] - 41s - loss: 8.0301 - mean_absolute_error: 2.4444 - val_loss: 8.0096 - val_mean_absolute_error: 2.4419\n",
      "Train on 800000 samples, validate on 200000 samples\n",
      "Epoch 1/3\n",
      "800000/800000 [==============================] - 38s - loss: 7.9964 - mean_absolute_error: 2.4395 - val_loss: 7.9816 - val_mean_absolute_error: 2.4373\n",
      "Epoch 2/3\n",
      "800000/800000 [==============================] - 35s - loss: 7.9910 - mean_absolute_error: 2.4385 - val_loss: 7.9808 - val_mean_absolute_error: 2.4378\n",
      "Epoch 3/3\n",
      "800000/800000 [==============================] - 36s - loss: 7.9900 - mean_absolute_error: 2.4382 - val_loss: 7.9833 - val_mean_absolute_error: 2.4388\n",
      "Train on 800000 samples, validate on 200000 samples\n",
      "Epoch 1/3\n",
      "800000/800000 [==============================] - 33s - loss: 7.9860 - mean_absolute_error: 2.4379 - val_loss: 7.9786 - val_mean_absolute_error: 2.4370\n",
      "Epoch 2/3\n",
      "800000/800000 [==============================] - 35s - loss: 7.9856 - mean_absolute_error: 2.4377 - val_loss: 7.9790 - val_mean_absolute_error: 2.4375\n",
      "Epoch 3/3\n",
      "800000/800000 [==============================] - 37s - loss: 7.9862 - mean_absolute_error: 2.4378 - val_loss: 7.9787 - val_mean_absolute_error: 2.4370\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11b286748>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train regression model\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "m_reg.compile(optimizer=sgd,loss='mean_squared_error',metrics=['mae'])\n",
    "m_reg.fit(x=X,y=Y_reg,batch_size=64,nb_epoch=2,validation_split=0.2)\n",
    "sgd = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "m_reg.layers[2] = Dropout(0.)\n",
    "m_reg.layers[5] = Dropout(0.)\n",
    "m_reg.compile(optimizer=sgd,loss='mean_squared_error',metrics=['mae'])\n",
    "m_reg.fit(x=X,y=Y_reg,batch_size=64,nb_epoch=1,validation_split=0.2)\n",
    "sgd = SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "m_reg.compile(optimizer=sgd,loss='mean_squared_error',metrics=['mae'])\n",
    "m_reg.fit(x=X,y=Y_reg,batch_size=64,nb_epoch=1,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800000 samples, validate on 200000 samples\n",
      "Epoch 1/2\n",
      "800000/800000 [==============================] - 45s - loss: 5.8559 - acc: 0.0961 - val_loss: 5.8100 - val_acc: 0.1172\n",
      "Epoch 2/2\n",
      "800000/800000 [==============================] - 45s - loss: 5.8555 - acc: 0.0940 - val_loss: 5.8089 - val_acc: 0.1020\n",
      "Train on 800000 samples, validate on 200000 samples\n",
      "Epoch 1/1\n",
      "800000/800000 [==============================] - 44s - loss: 5.8468 - acc: 0.0938 - val_loss: 5.7975 - val_acc: 0.1097\n",
      "Train on 800000 samples, validate on 200000 samples\n",
      "Epoch 1/1\n",
      "800000/800000 [==============================] - 42s - loss: 5.8439 - acc: 0.0939 - val_loss: 5.7967 - val_acc: 0.1111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x140ce3a20>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train softmax model\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "m_sm.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "m_sm.fit(x=X,y=Y_sm_half,batch_size=64,nb_epoch=2,validation_split=0.2)\n",
    "sgd = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "m_sm.layers[2] = Dropout(0.)\n",
    "m_sm.layers[5] = Dropout(0.)\n",
    "m_sm.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "m_sm.fit(x=X,y=Y_sm_half,batch_size=64,nb_epoch=1,validation_split=0.2)\n",
    "sgd = SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "m_sm.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "m_sm.fit(x=X,y=Y_sm_half,batch_size=64,nb_epoch=1,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.17538571  3.24850011  4.63944006  4.9945178   4.85439539]\n",
      "[5 4 1 4 7]\n",
      "[ 4.29260015  4.30029583  5.08920574  4.69491196  4.74303722]\n",
      "[2 9 0 9 8]\n",
      "mean proportion error 0.13\n"
     ]
    }
   ],
   "source": [
    "k = 100\n",
    "y_pred = m_reg.predict(X[0:k,:])\n",
    "y1_pred = y_pred[:,0]\n",
    "y2_pred = y_pred[:,1]\n",
    "y1_true = Y_reg[:k,0]\n",
    "y2_true = Y_reg[:k,1]\n",
    "print(y1_pred[0:5])\n",
    "print(y1_true[0:5])\n",
    "print(y2_pred[0:5])\n",
    "print(y2_true[0:5])\n",
    "\n",
    "mae = (np.abs(y1_pred-y1_true) + np.abs(y2_pred-y2_true)).sum()/2/k/(w-1)\n",
    "print('mean proportion error %.2f' % mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32/100 [========>.....................] - ETA: 0s[0 4 2 6 4 6 2 2 0 2 2 2 0 0 5 2 2 6 1 0 3 0 0 0 5 1 2 0 2 3 2 0 5 2 2 1 0\n",
      " 5 2 1 1 1 2 4 6 4 3 2 0 4 1 0 3 1 4 3 0 5 0 2 1 2 4 0 2 3 6 5 1 0 0 3 0 0\n",
      " 1 3 2 5 3 1 3 2 2 2 0 0 1 1 1 2 0 4 2 1 2 3 2 0 1 2]\n",
      "[5 4 1 4 7 9 1 6 6 7 2 2 2 1 2 5 0 8 1 5 3 2 5 6 6 3 2 4 3 3 9 0 5 6 0 1 9\n",
      " 5 0 6 8 2 0 1 5 6 4 2 8 4 8 5 3 9 0 6 6 3 7 2 6 9 2 9 2 4 6 9 3 8 2 5 8 7\n",
      " 2 1 9 4 1 6 2 6 7 6 5 8 1 4 6 3 1 7 3 7 7 7 6 5 8 8]\n",
      "[8 4 9 9 1 9 2 9 5 4 8 9 2 5 3 1 6 0 0 1 8 4 9 6 5 3 1 2 8 9 2 7 8 6 1 0 9\n",
      " 3 9 1 7 4 0 3 7 8 9 2 1 0 5 4 9 0 6 7 7 0 7 7 7 4 4 0 7 7 7 0 5 0 9 6 6 5\n",
      " 0 3 2 6 3 6 9 9 6 1 1 5 8 8 3 8 2 5 5 7 8 8 0 4 3 8]\n",
      "[0 7 9 9 6 9 9 7 4 1 4 2 6 3 0 6 8 4 3 3 4 3 5 0 6 2 8 8 7 0 3 3 4 4 0 0 2\n",
      " 1 0 5 1 1 2 0 2 3 7 9 4 8 1 3 2 5 5 3 7 0 5 8 2 3 2 2 2 4 3 4 8 8 2 4 0 8\n",
      " 5 8 7 1 2 2 3 2 7 0 9 5 4 3 4 3 1 2 8 0 3 6 4 4 4 7]\n",
      "accuracy 0.130\n",
      "mean proportion error 0.18\n"
     ]
    }
   ],
   "source": [
    "k = 100\n",
    "y_pred = m_sm.predict_proba(X[0:k,:])\n",
    "y1_pred = y_pred[:,0:w].argmax(axis=1)\n",
    "y2_pred = y_pred[:,w:(2*w)].argmax(axis=1)\n",
    "y1_true = Y_sm[0:k].argmax(axis=1)\n",
    "y2_true = Y_sm[k:(2*k)].argmax(axis=1)\n",
    "print(y1_pred)\n",
    "print(y1_true)\n",
    "print(y2_pred)\n",
    "print(y2_true)\n",
    "acc = ((y1_pred==y1_true).sum()+(y2_pred==y2_true).sum())/2/k\n",
    "print('accuracy %.3f' % acc)\n",
    "mae = (np.abs(y1_pred-y1_true) + np.abs(y2_pred-y2_true)).sum()/2/k/(w-1)\n",
    "print('mean proportion error %.2f' % mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in the above 2 comparisons, the regression and single softmax doesn't seem to work very well in detecting the 'max pixel' from a w\\*w grid. We now try augmenting the final output with 2 different softmaxes, 1 for each dimension. This will require the use of the functional api, since we're forking the outputs from the fc layer into 2 softmaxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(0)\n",
    "n = 1000000\n",
    "h = 6\n",
    "w = 10\n",
    "k = 500000\n",
    "X = np.round(rng.uniform(low=-1,high=1,size=(n,h*w)),decimals=2)\n",
    "X_test = np.round(rng.uniform(low=-1,high=1,size=(k,h*w)),decimals=2)\n",
    "\n",
    "# prepare Y outputs for regression\n",
    "y1_reg = np.int16(X.argmax(axis=1)/w).reshape((n,1)) # h, y\n",
    "y2_reg = np.int16(X.argmax(axis=1)%w).reshape((n,1)) # w, x\n",
    "y1_reg_test = np.int16(X_test.argmax(axis=1)/w).reshape((k,1)) # h, y\n",
    "y2_reg_test = np.int16(X_test.argmax(axis=1)%w).reshape((k,1)) # w, x\n",
    "\n",
    "# prepare Y outputs for softmax\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "enc.fit(np.arange(h).reshape(h,1))\n",
    "y1_sm = enc.transform(y1_reg)\n",
    "y1_sm_test = enc.transform(y1_reg_test)\n",
    "enc.fit(np.arange(w).reshape(w,1))\n",
    "y2_sm = enc.transform(y2_reg)\n",
    "y2_sm_test = enc.transform(y2_reg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.1   0.43  0.21  0.09 -0.15  0.29 -0.12  0.78  0.93 -0.23]\n",
      "  [ 0.58  0.06  0.14  0.85 -0.86 -0.83 -0.96  0.67  0.56  0.74]\n",
      "  [ 0.96  0.6  -0.08  0.56 -0.76  0.28 -0.71  0.89  0.04 -0.17]\n",
      "  [-0.47  0.55 -0.09  0.14 -0.96  0.24  0.22  0.23  0.89  0.36]\n",
      "  [-0.28 -0.13  0.4  -0.88  0.33  0.34 -0.58 -0.74 -0.37 -0.27]\n",
      "  [ 0.14 -0.12  0.98 -0.8  -0.58 -0.68  0.31 -0.49 -0.07 -0.51]]\n",
      "\n",
      " [[-0.68 -0.78  0.31 -0.72 -0.61 -0.26  0.64 -0.81  0.68 -0.81]\n",
      "  [ 0.95 -0.06  0.95  0.21  0.48 -0.92 -0.43 -0.76 -0.41 -0.76]\n",
      "  [-0.36 -0.17 -0.87  0.38  0.13 -0.47  0.05 -0.81  0.15  0.86]\n",
      "  [-0.36  0.33 -0.74  0.43 -0.42 -0.63  0.17 -0.96  0.66 -0.99]\n",
      "  [ 0.36 -0.46  0.47  0.92 -0.5   0.15  0.18  0.14 -0.55  0.91]\n",
      "  [-0.11  0.69  0.4  -0.41  0.63 -0.21  0.76  0.16  0.76  0.39]]\n",
      "\n",
      " [[ 0.45  0.    0.91  0.29 -0.15  0.21 -0.96 -0.4   0.32 -0.42]\n",
      "  [ 0.24 -0.14 -0.73 -0.4   0.14  0.18  0.15  0.31  0.3  -0.14]\n",
      "  [ 0.79 -0.26 -0.13  0.78  0.61  0.41 -0.8   0.84  0.43  1.  ]\n",
      "  [-0.7   0.74 -0.68  0.23 -0.75  0.7   0.61  0.14 -0.19 -0.86]\n",
      "  [ 0.39 -0.09  0.44  0.73  0.95  0.71 -0.98 -0.28  0.46 -0.66]\n",
      "  [ 0.04 -0.89 -0.6  -0.96  0.59 -0.55 -0.31  0.86  0.41 -0.94]]\n",
      "\n",
      " [[-0.67  0.24  0.15 -0.52  0.87  0.23  0.07  0.18  0.46 -0.38]\n",
      "  [-0.2  -0.58 -0.63  0.89  0.48 -0.02 -0.55 -0.49 -0.88 -0.13]\n",
      "  [-0.38  0.39 -0.24 -0.64 -0.95 -0.87  0.36 -0.09  0.07  0.79]\n",
      "  [ 0.98 -0.57  0.33 -0.47 -0.96  0.52 -0.36 -0.23  0.18  0.66]\n",
      "  [ 0.26  0.75 -0.45  0.6  -0.63  0.91  0.37 -0.57  0.89  0.46]\n",
      "  [-0.49 -0.57  0.04 -0.95 -0.59 -0.15 -0.25 -0.07 -0.44  0.17]]\n",
      "\n",
      " [[ 0.73 -0.76  0.03 -0.74  0.43 -0.21  0.13 -0.63 -0.71 -0.02]\n",
      "  [-0.29  0.88  0.53  0.5   0.81 -0.83  0.1   0.17  0.92 -0.42]\n",
      "  [-0.52 -0.8  -0.97  0.86  0.34  0.57 -0.44  0.17 -0.87 -0.03]\n",
      "  [ 0.95  0.75 -0.32  0.92 -0.54  0.9   0.88  0.6   0.26  0.75]\n",
      "  [-0.41  0.7   0.24 -0.97 -0.31 -0.7   0.96 -0.04 -0.01  0.28]\n",
      "  [-0.26 -0.73  0.64 -0.62  0.02 -0.55 -0.8   0.72  0.95  0.92]]]\n",
      "[[5]\n",
      " [1]\n",
      " [2]\n",
      " [3]\n",
      " [4]]\n",
      "[[2]\n",
      " [0]\n",
      " [9]\n",
      " [0]\n",
      " [6]]\n",
      "[[ 0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]]\n",
      "[[ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print(X[0:5,:].reshape((5,h,w)))\n",
    "print(y1_reg[0:5,:])\n",
    "print(y2_reg[0:5,:])\n",
    "print(y1_sm[0:5,:])\n",
    "print(y2_sm[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.63 -0.15 -0.51  0.19 -0.66  0.51  0.74  0.02  0.36 -0.61]\n",
      "  [-0.17  0.06 -0.22  0.39  0.51 -0.52  0.16 -0.76  0.82 -0.82]\n",
      "  [-0.45  0.55  0.22 -0.36 -0.07  0.68  0.03 -0.36  0.02  0.13]\n",
      "  [-0.99 -0.21  0.02  0.12 -0.03 -0.78  0.35  0.3  -0.16 -0.4 ]\n",
      "  [ 0.09  0.67 -0.57  0.09 -0.98  0.15  0.04 -0.27  0.09  0.67]\n",
      "  [-0.52 -0.58 -0.04  0.41 -0.81 -0.79  0.78  0.19 -0.02  0.46]]\n",
      "\n",
      " [[-0.09 -0.62  0.46  0.73 -0.    0.8   0.36  0.28  0.93 -0.27]\n",
      "  [-0.   -0.    0.54  0.62  0.53 -0.2  -0.09 -0.62 -0.93 -0.55]\n",
      "  [ 0.43  0.6  -0.73  0.18 -0.39 -0.12  0.82  0.1  -0.46  0.1 ]\n",
      "  [ 0.12 -0.96 -0.38 -0.68 -0.87 -0.54 -0.33  0.5  -0.22  0.1 ]\n",
      "  [-0.96  0.31 -0.63 -0.79 -0.19  0.11  0.89  0.11  0.1  -0.09]\n",
      "  [ 0.83  0.11  0.28 -0.88 -0.33  0.81  0.25  0.65  0.89 -0.98]]\n",
      "\n",
      " [[-0.2  -0.83  0.08  0.66 -0.29 -0.59 -0.68 -0.46 -0.58 -0.39]\n",
      "  [ 0.85 -0.45  0.49  0.5  -0.16  0.57  0.4   0.97  0.75  0.93]\n",
      "  [-0.22  0.5   0.64  0.7   0.21 -0.45  0.59  0.52 -0.66 -0.93]\n",
      "  [-0.58  0.98 -0.94 -0.79  0.05 -0.72 -0.14 -0.07  0.8  -0.49]\n",
      "  [ 0.65  0.49 -0.36 -0.12  0.07  0.06 -0.88  0.25  0.2   0.5 ]\n",
      "  [-0.2   0.71  0.24 -0.09  0.74  0.6   0.01  0.69  0.43  0.99]]\n",
      "\n",
      " [[ 0.55 -0.69  1.    0.66  0.45  0.4  -0.51 -0.82 -0.31  0.55]\n",
      "  [ 0.33  0.62 -0.98  0.38 -0.74  0.21 -0.02 -0.94 -0.75  0.32]\n",
      "  [ 0.54  0.55  0.99  0.52 -0.33 -0.66  0.95 -0.39  0.28  0.11]\n",
      "  [ 0.81 -0.74  0.53  0.82 -0.02 -0.22 -0.06  0.7  -0.51  1.  ]\n",
      "  [ 0.34  0.94  0.28 -0.81  0.3   0.88  0.99 -0.65  0.32  0.95]\n",
      "  [ 0.91  0.43  0.54 -0.04 -0.64 -0.88  0.65 -0.23  0.8   0.98]]\n",
      "\n",
      " [[-0.24 -0.14  0.86 -0.07  0.86  0.1   0.26 -0.5  -0.08  0.04]\n",
      "  [ 0.08  0.08  0.99  0.4  -0.98 -0.16 -0.72  0.57  0.51  0.97]\n",
      "  [-0.28 -0.28 -0.18 -0.7   0.51  0.22  0.71  0.63 -0.92 -0.9 ]\n",
      "  [-0.53  0.23 -0.2  -0.73 -0.75  0.66 -0.94 -1.    0.18  0.67]\n",
      "  [-0.68 -0.81  0.09  0.38  0.75  0.88 -0.74  0.79 -0.4   0.3 ]\n",
      "  [ 0.2  -0.13 -0.56 -0.91  0.31  0.56  0.47 -0.87  0.28  0.25]]]\n",
      "[[1]\n",
      " [0]\n",
      " [5]\n",
      " [0]\n",
      " [1]]\n",
      "[[8]\n",
      " [8]\n",
      " [9]\n",
      " [2]\n",
      " [2]]\n",
      "[[ 0.  1.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.]\n",
      " [ 1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test[0:5,:].reshape((5,h,w)))\n",
    "print(y1_reg_test[0:5,:])\n",
    "print(y2_reg_test[0:5,:])\n",
    "print(y1_sm_test[0:5,:])\n",
    "print(y2_sm_test[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Convolution2D, MaxPooling2D, ZeroPadding2D, Layer, \\\n",
    "    Activation, Dropout, Flatten, MaxoutDense, Dense, merge\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "# custom layer for getting max,Â mean for over each vertical strip\n",
    "class VerticalAgg(Layer):\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        shape = list(input_shape)\n",
    "        assert len(shape) == 4  # only valid for 4D tensors (batch_size,h,w,ch)\n",
    "        return (input_shape[0],input_shape[2]*2,input_shape[3]) # (batch_size,2w,ch)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        return merge([K.max(x, axis=1, keepdims=False), \n",
    "                     K.mean(x, axis=1, keepdims=False)], \n",
    "                     mode='concat', concat_axis=1)\n",
    "\n",
    "\n",
    "    \n",
    "# custom layer for getting max for over each horizontal strip\n",
    "class HorizontalMax(Layer):\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        shape = list(input_shape)\n",
    "        assert len(shape) == 4  # only valid for 4D tensors (batch_size,h,w,ch)\n",
    "        return (input_shape[0],input_shape[1],input_shape[3]) # (batch_size,h,ch)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        return K.max(x, axis=2, keepdims=False)\n",
    "\n",
    "X_conv = X.reshape((n,h,w,1))\n",
    "X_conv_test = X_test.reshape((k,h,w,1))\n",
    "\n",
    "inputs = Input(shape=(h,w,1))\n",
    "\n",
    "x_pool = VerticalAgg()(inputs)\n",
    "x_flat = Flatten()(x_pool)\n",
    "x_dense = Dense(16, activation='relu')(x_flat)\n",
    "x_out = Dense(w, activation='softmax')(x_dense)\n",
    "\n",
    "y_pool = HorizontalMax()(inputs)\n",
    "y_flat = Flatten()(y_pool)\n",
    "y_dense = Dense(16, activation='relu')(y_flat)\n",
    "y_out = Dense(h, activation='softmax')(y_dense)\n",
    "\n",
    "m2_sm = Model(input=[inputs], output=[y_out,x_out])\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "m2_sm.compile(optimizer=sgd, loss='categorical_crossentropy',\n",
    "              loss_weights=[0.5, 0.5], metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800000 samples, validate on 200000 samples\n",
      "Epoch 1/10\n",
      "800000/800000 [==============================] - 62s - loss: 0.7510 - dense_26_loss: 0.6069 - dense_24_loss: 0.8952 - dense_26_acc: 0.8518 - dense_24_acc: 0.7378 - val_loss: 0.3352 - val_dense_26_loss: 0.2602 - val_dense_24_loss: 0.4102 - val_dense_26_acc: 0.9765 - val_dense_24_acc: 0.9070\n",
      "Epoch 2/10\n",
      "800000/800000 [==============================] - 60s - loss: 0.2731 - dense_26_loss: 0.2098 - dense_24_loss: 0.3364 - dense_26_acc: 0.9635 - dense_24_acc: 0.9082 - val_loss: 0.2296 - val_dense_26_loss: 0.1745 - val_dense_24_loss: 0.2848 - val_dense_26_acc: 0.9696 - val_dense_24_acc: 0.9162\n",
      "Epoch 3/10\n",
      "800000/800000 [==============================] - 61s - loss: 0.2067 - dense_26_loss: 0.1541 - dense_24_loss: 0.2592 - dense_26_acc: 0.9737 - dense_24_acc: 0.9186 - val_loss: 0.1886 - val_dense_26_loss: 0.1432 - val_dense_24_loss: 0.2341 - val_dense_26_acc: 0.9623 - val_dense_24_acc: 0.9244\n",
      "Epoch 4/10\n",
      " 94784/800000 [==>...........................] - ETA: 54s - loss: 0.1872 - dense_26_loss: 0.1375 - dense_24_loss: 0.2368 - dense_26_acc: 0.9754 - dense_24_acc: 0.9212"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-1cdf73b7e0da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm2_sm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_conv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my1_sm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my2_sm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/jingpingw/anaconda/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch)\u001b[0m\n\u001b[1;32m   1141\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1143\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jingpingw/anaconda/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m    841\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jingpingw/anaconda/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1601\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1602\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 1603\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   1604\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jingpingw/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jingpingw/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jingpingw/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/jingpingw/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jingpingw/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1001\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "m2_sm.fit(x=[X_conv],y=[y1_sm,y2_sm],batch_size=64,nb_epoch=10,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800000 samples, validate on 200000 samples\n",
      "Epoch 1/10\n",
      "800000/800000 [==============================] - 62s - loss: 0.7632 - dense_18_loss: 0.6029 - dense_16_loss: 0.9236 - dense_18_acc: 0.8527 - dense_16_acc: 0.7389 - val_loss: 0.3382 - val_dense_18_loss: 0.2657 - val_dense_16_loss: 0.4107 - val_dense_18_acc: 0.9454 - val_dense_16_acc: 0.9119\n",
      "Epoch 2/10\n",
      "800000/800000 [==============================] - 62s - loss: 0.2737 - dense_18_loss: 0.2108 - dense_16_loss: 0.3365 - dense_18_acc: 0.9624 - dense_16_acc: 0.9105 - val_loss: 0.2271 - val_dense_18_loss: 0.1674 - val_dense_16_loss: 0.2868 - val_dense_18_acc: 0.9922 - val_dense_16_acc: 0.9123\n",
      "Epoch 3/10\n",
      "800000/800000 [==============================] - 58s - loss: 0.2066 - dense_18_loss: 0.1551 - dense_16_loss: 0.2581 - dense_18_acc: 0.9726 - dense_16_acc: 0.9203 - val_loss: 0.1865 - val_dense_18_loss: 0.1363 - val_dense_16_loss: 0.2368 - val_dense_18_acc: 0.9801 - val_dense_16_acc: 0.9248\n",
      "Epoch 4/10\n",
      "800000/800000 [==============================] - 58s - loss: 0.1757 - dense_18_loss: 0.1279 - dense_16_loss: 0.2235 - dense_18_acc: 0.9777 - dense_16_acc: 0.9243 - val_loss: 0.1675 - val_dense_18_loss: 0.1209 - val_dense_16_loss: 0.2141 - val_dense_18_acc: 0.9730 - val_dense_16_acc: 0.9228\n",
      "Epoch 5/10\n",
      "800000/800000 [==============================] - 61s - loss: 0.1571 - dense_18_loss: 0.1111 - dense_16_loss: 0.2032 - dense_18_acc: 0.9810 - dense_16_acc: 0.9262 - val_loss: 0.1437 - val_dense_18_loss: 0.1034 - val_dense_16_loss: 0.1839 - val_dense_18_acc: 0.9836 - val_dense_16_acc: 0.9334\n",
      "Epoch 6/10\n",
      "800000/800000 [==============================] - 61s - loss: 0.1448 - dense_18_loss: 0.0992 - dense_16_loss: 0.1904 - dense_18_acc: 0.9834 - dense_16_acc: 0.9274 - val_loss: 0.1321 - val_dense_18_loss: 0.0906 - val_dense_16_loss: 0.1736 - val_dense_18_acc: 0.9883 - val_dense_16_acc: 0.9341\n",
      "Epoch 7/10\n",
      "800000/800000 [==============================] - 63s - loss: 0.1357 - dense_18_loss: 0.0903 - dense_16_loss: 0.1812 - dense_18_acc: 0.9848 - dense_16_acc: 0.9283 - val_loss: 0.1308 - val_dense_18_loss: 0.0823 - val_dense_16_loss: 0.1793 - val_dense_18_acc: 0.9936 - val_dense_16_acc: 0.9286\n",
      "Epoch 8/10\n",
      "800000/800000 [==============================] - 63s - loss: 0.1288 - dense_18_loss: 0.0832 - dense_16_loss: 0.1744 - dense_18_acc: 0.9865 - dense_16_acc: 0.9294 - val_loss: 0.1285 - val_dense_18_loss: 0.0860 - val_dense_16_loss: 0.1709 - val_dense_18_acc: 0.9801 - val_dense_16_acc: 0.9292\n",
      "Epoch 9/10\n",
      "800000/800000 [==============================] - 66s - loss: 0.1234 - dense_18_loss: 0.0774 - dense_16_loss: 0.1694 - dense_18_acc: 0.9878 - dense_16_acc: 0.9299 - val_loss: 0.1225 - val_dense_18_loss: 0.0720 - val_dense_16_loss: 0.1731 - val_dense_18_acc: 0.9913 - val_dense_16_acc: 0.9274\n",
      "Epoch 10/10\n",
      "800000/800000 [==============================] - 60s - loss: 0.1187 - dense_18_loss: 0.0722 - dense_16_loss: 0.1652 - dense_18_acc: 0.9889 - dense_16_acc: 0.9303 - val_loss: 0.1186 - val_dense_18_loss: 0.0703 - val_dense_16_loss: 0.1669 - val_dense_18_acc: 0.9861 - val_dense_16_acc: 0.9305\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x118ce3e48>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2_sm.fit(x=[X_conv],y=[y1_sm,y2_sm],batch_size=64,nb_epoch=10,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 5 0 1 1 0 2 1 5 0 3 4 1 0 4 4 2 5 4]\n",
      "[1 0 5 0 1 1 0 2 1 5 0 3 4 1 0 4 4 2 5 4]\n",
      "[8 8 9 2 2 3 3 5 7 0 7 2 0 4 0 2 4 6 4 6]\n",
      "[8 8 9 2 2 3 3 5 7 0 7 2 0 4 0 2 4 6 4 6]\n",
      "accuracy 0.958\n",
      "mean proportion error for x 0.00\n",
      "mean proportion error for y 0.05\n"
     ]
    }
   ],
   "source": [
    "# predict on X_test\n",
    "y_pred = m2_sm.predict(X_conv_test)\n",
    "y1_pred = y_pred[0].argmax(axis=1)\n",
    "y2_pred = y_pred[1].argmax(axis=1)\n",
    "y1_true = y1_sm_test.argmax(axis=1)\n",
    "y2_true = y2_sm_test.argmax(axis=1)\n",
    "print(y1_pred[:20])\n",
    "print(y1_true[:20])\n",
    "print(y2_pred[:20])\n",
    "print(y2_true[:20])\n",
    "acc = (np.equal(y1_pred,y1_true).mean()+np.equal(y2_pred,y2_true).mean())/2\n",
    "print('accuracy %.3f' % acc)\n",
    "mae_x = (np.abs(y1_pred-y1_true)).mean()/(w-1)\n",
    "mae_y = (np.abs(y2_pred-y2_true)).mean()/(h-1)\n",
    "print('mean proportion error for x %.2f' % mae_x)\n",
    "print('mean proportion error for y %.2f' % mae_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's quite a bit of an improvement! Nevertheless, let's try a regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = Input(shape=(h,w,1))\n",
    "\n",
    "x_pool = VerticalMax()(inputs)\n",
    "x_flat = Flatten()(x_pool)\n",
    "x_dense = Dense(16, activation='relu')(x_flat)\n",
    "x_out = Dense(1, activation='relu')(x_dense)\n",
    "\n",
    "y_pool = HorizontalMax()(inputs)\n",
    "y_flat = Flatten()(y_pool)\n",
    "y_dense = Dense(16, activation='relu')(y_flat)\n",
    "y_out = Dense(1, activation='relu')(y_dense)\n",
    "\n",
    "m2_reg = Model(input=[inputs], output=[y_out,x_out])\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "m2_reg.compile(optimizer=sgd, loss='mean_squared_error',\n",
    "              loss_weights=[0.5, 0.5], metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800000 samples, validate on 200000 samples\n",
      "Epoch 1/10\n",
      "800000/800000 [==============================] - 51s - loss: 2.4791 - dense_22_loss: 1.0909 - dense_20_loss: 3.8674 - dense_22_mean_absolute_error: 0.7934 - dense_20_mean_absolute_error: 1.5529 - val_loss: 2.4637 - val_dense_22_loss: 1.0537 - val_dense_20_loss: 3.8738 - val_dense_22_mean_absolute_error: 0.7769 - val_dense_20_mean_absolute_error: 1.5520\n",
      "Epoch 2/10\n",
      "800000/800000 [==============================] - 53s - loss: 2.4669 - dense_22_loss: 1.0829 - dense_20_loss: 3.8509 - dense_22_mean_absolute_error: 0.7899 - dense_20_mean_absolute_error: 1.5486 - val_loss: 2.3972 - val_dense_22_loss: 1.0701 - val_dense_20_loss: 3.7244 - val_dense_22_mean_absolute_error: 0.7986 - val_dense_20_mean_absolute_error: 1.5155\n",
      "Epoch 3/10\n",
      "800000/800000 [==============================] - 52s - loss: 2.4578 - dense_22_loss: 1.0771 - dense_20_loss: 3.8384 - dense_22_mean_absolute_error: 0.7879 - dense_20_mean_absolute_error: 1.5445 - val_loss: 2.4092 - val_dense_22_loss: 1.0457 - val_dense_20_loss: 3.7728 - val_dense_22_mean_absolute_error: 0.7732 - val_dense_20_mean_absolute_error: 1.5274\n",
      "Epoch 4/10\n",
      "800000/800000 [==============================] - 50s - loss: 2.4527 - dense_22_loss: 1.0722 - dense_20_loss: 3.8332 - dense_22_mean_absolute_error: 0.7860 - dense_20_mean_absolute_error: 1.5427 - val_loss: 2.3437 - val_dense_22_loss: 1.0338 - val_dense_20_loss: 3.6536 - val_dense_22_mean_absolute_error: 0.7711 - val_dense_20_mean_absolute_error: 1.5159\n",
      "Epoch 5/10\n",
      "800000/800000 [==============================] - 49s - loss: 2.4489 - dense_22_loss: 1.0657 - dense_20_loss: 3.8322 - dense_22_mean_absolute_error: 0.7843 - dense_20_mean_absolute_error: 1.5425 - val_loss: 2.4886 - val_dense_22_loss: 1.0437 - val_dense_20_loss: 3.9334 - val_dense_22_mean_absolute_error: 0.7832 - val_dense_20_mean_absolute_error: 1.5795\n",
      "Epoch 6/10\n",
      "800000/800000 [==============================] - 53s - loss: 2.4445 - dense_22_loss: 1.0588 - dense_20_loss: 3.8303 - dense_22_mean_absolute_error: 0.7816 - dense_20_mean_absolute_error: 1.5407 - val_loss: 2.3414 - val_dense_22_loss: 1.0395 - val_dense_20_loss: 3.6433 - val_dense_22_mean_absolute_error: 0.7843 - val_dense_20_mean_absolute_error: 1.5064\n",
      "Epoch 7/10\n",
      "800000/800000 [==============================] - 45s - loss: 2.4420 - dense_22_loss: 1.0533 - dense_20_loss: 3.8307 - dense_22_mean_absolute_error: 0.7798 - dense_20_mean_absolute_error: 1.5406 - val_loss: 2.4132 - val_dense_22_loss: 1.0375 - val_dense_20_loss: 3.7888 - val_dense_22_mean_absolute_error: 0.7769 - val_dense_20_mean_absolute_error: 1.5315\n",
      "Epoch 8/10\n",
      "800000/800000 [==============================] - 54s - loss: 2.4343 - dense_22_loss: 1.0493 - dense_20_loss: 3.8193 - dense_22_mean_absolute_error: 0.7788 - dense_20_mean_absolute_error: 1.5375 - val_loss: 2.3348 - val_dense_22_loss: 1.0331 - val_dense_20_loss: 3.6365 - val_dense_22_mean_absolute_error: 0.7636 - val_dense_20_mean_absolute_error: 1.5208\n",
      "Epoch 9/10\n",
      "800000/800000 [==============================] - 50s - loss: 2.4354 - dense_22_loss: 1.0459 - dense_20_loss: 3.8249 - dense_22_mean_absolute_error: 0.7771 - dense_20_mean_absolute_error: 1.5383 - val_loss: 2.4966 - val_dense_22_loss: 1.0523 - val_dense_20_loss: 3.9408 - val_dense_22_mean_absolute_error: 0.7708 - val_dense_20_mean_absolute_error: 1.5698\n",
      "Epoch 10/10\n",
      "800000/800000 [==============================] - 48s - loss: 2.4329 - dense_22_loss: 1.0429 - dense_20_loss: 3.8229 - dense_22_mean_absolute_error: 0.7755 - dense_20_mean_absolute_error: 1.5375 - val_loss: 2.3956 - val_dense_22_loss: 1.0133 - val_dense_20_loss: 3.7778 - val_dense_22_mean_absolute_error: 0.7609 - val_dense_20_mean_absolute_error: 1.5230\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11af66908>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2_reg.fit(x=[X_conv],y=[y1_reg,y2_reg],batch_size=64,nb_epoch=10,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 1), (100, 1))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = m2_reg.predict(X_conv[0:k,...])\n",
    "y_pred[0].shape,y_pred[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.74435997]\n",
      " [ 1.80402732]\n",
      " [ 3.20696402]\n",
      " [ 0.33051264]\n",
      " [ 0.24506938]]\n",
      "[[1]\n",
      " [0]\n",
      " [5]\n",
      " [0]\n",
      " [1]]\n",
      "[[ 6.33391571]\n",
      " [ 5.3895359 ]\n",
      " [ 7.62091827]\n",
      " [ 6.93370247]\n",
      " [ 4.49849844]]\n",
      "[[8]\n",
      " [8]\n",
      " [9]\n",
      " [2]\n",
      " [2]]\n",
      "accuracy 0.332\n",
      "mean proportion error for x 0.08\n",
      "mean proportion error for y 0.30\n"
     ]
    }
   ],
   "source": [
    "y1_pred, y2_pred = m2_reg.predict(X_conv_test)\n",
    "y1_true = y1_reg_test\n",
    "y2_true = y2_reg_test\n",
    "print(y1_pred[:5])\n",
    "print(y1_true[:5])\n",
    "print(y2_pred[:5])\n",
    "print(y2_true[:5])\n",
    "acc = ((np.round(y1_pred)==y1_true).sum()+(np.round(y2_pred)==y2_true).sum())/2/k\n",
    "print('accuracy %.3f' % acc)\n",
    "mae_x = (np.abs(y1_pred-y1_true)).sum()/k/(w-1)\n",
    "mae_y = (np.abs(y2_pred-y2_true)).sum()/k/(h-1)\n",
    "print('mean proportion error for x %.2f' % mae_x)\n",
    "print('mean proportion error for y %.2f' % mae_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know that this architecture works for such inputs, what happens if we extend the size of the image and the outputs?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
